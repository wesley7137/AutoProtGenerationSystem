{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import ast\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "import asyncio\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def clear_cuda_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"CUDA cache cleared.\")\n",
    "    else:\n",
    "        print(\"CUDA is not available on this system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def clear_cuda_cache(show_memory_info=False):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA is not available on this system.\")\n",
    "        return\n",
    "\n",
    "    if show_memory_info:\n",
    "        print(f\"Before clearing - Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"Before clearing - Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    if show_memory_info:\n",
    "        print(f\"After clearing - Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"After clearing - Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "\n",
    "    print(\"CUDA cache cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, data_file, tokenizer, max_length=512):\n",
    "        self.data = pd.read_csv(data_file, sep=',', header=0)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        sequence = row['sequence']\n",
    "        advanced_description = row['advanced_description']\n",
    "        simple_description = row['simple_description']\n",
    "        go_terms = ast.literal_eval(row['go_terms'])\n",
    "        keywords = ast.literal_eval(row['keywords'])\n",
    "        function = row['function']\n",
    "        # Combine sequence and metadata for richer context\n",
    "        input_texts = [\n",
    "            f\"Sequence: {sequence} Description: {advanced_description} GO Terms: {' '.join(go_terms)} Keywords: {' '.join(keywords)}\",\n",
    "            f\"Sequence: {sequence} Description: {simple_description} GO Terms: {' '.join(go_terms)} Keywords: {' '.join(keywords)}\",\n",
    "            f\"Sequence: {sequence} Description: {function} GO Terms: {' '.join(go_terms)} Keywords: {' '.join(keywords)}\"\n",
    "        ]\n",
    "        \n",
    "        encodings = [self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        ) for text in input_texts]\n",
    "\n",
    "        return [{\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'sequence': sequence\n",
    "        } for encoding in encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinVAE(nn.Module):\n",
    "    def __init__(self, bert_model, latent_dim=128):\n",
    "        super(ProteinVAE, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.bert_output_dim = bert_model.config.hidden_size\n",
    "        self.vocab_size = bert_model.config.vocab_size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.bert_output_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim * 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1536)  # 3 * 512 = 1536\n",
    "        )\n",
    "        self.output = nn.Linear(1536, self.vocab_size * 1536)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def encode(self, x, attention_mask=None):\n",
    "        batch_size, num_descriptions, seq_length = x.shape\n",
    "        x = x.view(-1, seq_length)\n",
    "        attention_mask = attention_mask.view(-1, seq_length)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            bert_output = self.bert(x, attention_mask=attention_mask)[0]\n",
    "        bert_output = bert_output.view(batch_size, num_descriptions, seq_length, -1).mean(dim=[1, 2])\n",
    "        h = self.encoder(bert_output)\n",
    "        return h[:, :self.latent_dim], h[:, self.latent_dim:]\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder(z)\n",
    "        return self.output(h)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        batch_size, num_descriptions, seq_length = x.shape\n",
    "        mu, logvar = self.encode(x, attention_mask)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        decoded = self.decode(z)\n",
    "        # Reshape decoded output to match input shape\n",
    "        recon_x = decoded.view(batch_size, num_descriptions, seq_length, self.vocab_size)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    # Flatten the input and reconstructed tensors\n",
    "    recon_x_flat = recon_x.view(-1, recon_x.size(-1))\n",
    "    x_flat = x.view(-1)\n",
    "    \n",
    "    # Compute BCE loss\n",
    "    BCE = nn.functional.cross_entropy(recon_x_flat, x_flat, reduction='sum')\n",
    "    \n",
    "    # Compute KLD loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE + KLD\n",
    "\n",
    "# The rest of your code remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wes\\Miniconda3\\envs\\autoprot\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 41910.68359375\n",
      "Train Loss: 41483.14453125\n",
      "Train Loss: 41095.48046875\n",
      "Train Loss: 40734.8828125\n",
      "Train Loss: 40223.5390625\n",
      "Train Loss: 39738.07421875\n",
      "Train Loss: 39259.85546875\n",
      "Train Loss: 38566.21484375\n",
      "Train Loss: 37798.703125\n",
      "Train Loss: 37317.73828125\n",
      "Train Loss: 36139.05078125\n",
      "Train Loss: 35739.359375\n",
      "Train Loss: 34351.58984375\n",
      "Train Loss: 33700.54296875\n",
      "Train Loss: 32220.51171875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m vae_model \u001b[38;5;241m=\u001b[39m ProteinVAE(bert_model)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     84\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m load_protein_data(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvectordb_data_good\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmolT5_custom\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfully_merged_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m---> 85\u001b[0m \u001b[43mtrain_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvae_models\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m, in \u001b[0;36mtrain_vae\u001b[1;34m(vae_model, train_loader, val_loader, epochs, learning_rate, save_dir)\u001b[0m\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 39\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "def load_protein_data(file_path, tokenizer, batch_size=8, val_split=0.1):\n",
    "    dataset = ProteinDataset(file_path, tokenizer)\n",
    "    val_size = int(len(dataset) * val_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_vae(vae_model, train_loader, val_loader, epochs=20, learning_rate=1e-4, save_dir='models'):\n",
    "    optimizer = torch.optim.Adam(vae_model.parameters(), lr=learning_rate)\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        vae_model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "           \n",
    "            recon_batch, mu, logvar = vae_model(input_ids, attention_mask=attention_mask)\n",
    "            loss = vae_loss(recon_batch, input_ids.view(-1, input_ids.size(-1)), mu, logvar)\n",
    "           \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            print(f\"Train Loss: {loss.item()}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        vae_model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                \n",
    "                recon_batch, mu, logvar = vae_model(input_ids, attention_mask=attention_mask)\n",
    "                loss = vae_loss(recon_batch, input_ids.view(-1, input_ids.size(-1)), mu, logvar)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(vae_model.state_dict(), os.path.join(save_dir, 'best_vae_model.pth'))\n",
    "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    print(f\"Training completed. Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Main execution\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Freeze BERT parameters\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vae_model = ProteinVAE(bert_model).to(device)\n",
    "\n",
    "train_loader, val_loader = load_protein_data(r\"C:\\Users\\wes\\vectordb_data_good\\molT5_custom\\fully_merged_dataset.csv\", tokenizer, batch_size=8)\n",
    "train_vae(vae_model, train_loader, val_loader, epochs=20, save_dir='vae_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_protein_sequence(vae_model, tokenizer, max_length=256):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, vae_model.latent_dim).to(device)\n",
    "        decoded = vae_model.decode(z)\n",
    "        tokens = torch.argmax(decoded, dim=-1)\n",
    "        sequence = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the sequence part\n",
    "        if \"Sequence:\" in sequence:\n",
    "            sequence = sequence.split(\"Sequence:\")[1].split()[0]\n",
    "        \n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate and optimize sequences\n",
    "novel_sequences = [generate_protein_sequence(vae_model, tokenizer) for _ in range(5)]\n",
    "\n",
    "# Use your existing optimization pipeline here\n",
    "optimized_results = await run_optimization_pipeline(novel_sequences)\n",
    "\n",
    "for result in optimized_results:\n",
    "    print(f\"Generated sequence: {result['original_sequence'][:50]}...\")\n",
    "    print(f\"Optimized sequence: {result['optimized_sequence'][:50]}...\")\n",
    "    print(f\"Optimized score: {result['optimized_score']}\")\n",
    "    print(f\"Properties: {result['properties']}\")\n",
    "    print(\"---\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_protein_sequence(vae_model, tokenizer, max_length=256):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, vae_model.latent_dim).to(device)\n",
    "        decoded = vae_model.decode(z)\n",
    "        tokens = torch.argmax(decoded, dim=-1)\n",
    "        sequence = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract only the sequence part\n",
    "        if \"Sequence:\" in sequence:\n",
    "            sequence = sequence.split(\"Sequence:\")[1].split()[0]\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "# Main execution\n",
    "async def main():\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "    bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "    vae_model = ProteinVAE(bert_model).to(device)\n",
    "\n",
    "    data_loader = load_protein_data(\"path_to_your_protein_data.csv\", tokenizer)\n",
    "    train_vae(vae_model, data_loader, epochs=20)\n",
    "\n",
    "    # Generate and optimize sequences\n",
    "    novel_sequences = [generate_protein_sequence(vae_model, tokenizer) for _ in range(5)]\n",
    "    \n",
    "    # Use your existing optimization pipeline here\n",
    "    optimized_results = await run_optimization_pipeline(novel_sequences)\n",
    "\n",
    "    for result in optimized_results:\n",
    "        print(f\"Generated sequence: {result['original_sequence'][:50]}...\")\n",
    "        print(f\"Optimized sequence: {result['optimized_sequence'][:50]}...\")\n",
    "        print(f\"Optimized score: {result['optimized_scoreY']}\")\n",
    "        print(f\"Properties: {result['properties']}\")\n",
    "        print(\"---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wes\\Miniconda3\\envs\\autoprot\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\wes\\Miniconda3\\envs\\autoprot\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m vae_model \u001b[38;5;241m=\u001b[39m ProteinVAE(bert_model)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     90\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m load_protein_data(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvectordb_data_good\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmolT5_custom\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfully_merged_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m \u001b[43mtrain_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvae_models\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 34\u001b[0m, in \u001b[0;36mtrain_vae\u001b[1;34m(vae_model, train_loader, val_loader, epochs, learning_rate, save_dir)\u001b[0m\n\u001b[0;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(vae_model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 34\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m total_train_bce \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bce\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     36\u001b[0m total_train_kld \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m kld\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_vae(vae_model, train_loader, val_loader, epochs=20, learning_rate=5e-5, save_dir='models'):\n",
    "    optimizer = torch.optim.Adam(vae_model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    def compute_loss(recon_x, x, mu, logvar, kl_weight=0.01):\n",
    "        recon_x_flat = recon_x.view(-1, recon_x.size(-1))\n",
    "        x_flat = x.view(-1)\n",
    "        BCE = nn.functional.cross_entropy(recon_x_flat, x_flat, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + kl_weight * KLD, BCE, KLD\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        vae_model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_bce = 0\n",
    "        total_train_kld = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "           \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "           \n",
    "            recon_batch, mu, logvar = vae_model(input_ids, attention_mask=attention_mask)\n",
    "            loss, bce, kld = compute_loss(recon_batch, input_ids, mu, logvar)\n",
    "           \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae_model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            total_train_bce += bce.item()\n",
    "            total_train_kld += kld.item()\n",
    "            print(f\"Train Loss: {loss.item()}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "           \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_train_bce = total_train_bce / len(train_loader)\n",
    "        avg_train_kld = total_train_kld / len(train_loader)\n",
    "       \n",
    "        # Validation\n",
    "        vae_model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_bce = 0\n",
    "        total_val_kld = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "               \n",
    "                recon_batch, mu, logvar = vae_model(input_ids, attention_mask=attention_mask)\n",
    "                loss, bce, kld = compute_loss(recon_batch, input_ids, mu, logvar)\n",
    "                total_val_loss += loss.item()\n",
    "                total_val_bce += bce.item()\n",
    "                total_val_kld += kld.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        avg_val_bce = total_val_bce / len(val_loader)\n",
    "        avg_val_kld = total_val_kld / len(val_loader)\n",
    "       \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f} (BCE: {avg_val_bce:.4f}, KLD: {avg_val_kld:.4f})\")\n",
    "       \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Save the best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(vae_model.state_dict(), os.path.join(save_dir, 'best_vae_model.pth'))\n",
    "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    print(f\"Training completed. Best validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "# Main execution\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Freeze BERT parameters\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vae_model = ProteinVAE(bert_model).to(device)\n",
    "\n",
    "train_loader, val_loader = load_protein_data(r\"C:\\Users\\wes\\vectordb_data_good\\molT5_custom\\fully_merged_dataset.csv\", tokenizer, batch_size=8)\n",
    "train_vae(vae_model, train_loader, val_loader, epochs=20, save_dir='vae_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
